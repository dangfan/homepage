---
title: "Enhancing Large Language Models with Knowledge Graphs for Robust Question Answering"
authors:
- Zhui Zhu
- Guangpeng Qi
- Guangyong Shang
- Qingfeng He
- Weichen Zhang
- Ningbo Li
- Yunzhi Chen
- Lijun Hu
- Wenqiang Zhang
- Fan Dang
date: "2024-12-01T00:00:00Z"
doi: "10.1109/ICPADS63350.2024.00042"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["1"]

# Publication name and optional abbreviated publication name.
publication: In *Proceedings of the 30th IEEE International Conference on Parallel and Distributed Systems*
publication_short: In *IEEE ICPADS 2024*

abstract: In recent years, large language models (LLMs) have shown rapid development, becoming one of the most popular topics in the field of artificial intelligence. LLMs have demonstrated powerful generalization and learning capabilities, and their performance on various language tasks has been remarkable. Despite their successes, LLMs face significant challenges, particularly in domain-specific tasks that require structured knowledge, often leading to issues such as hallucinations. To mitigate these challenges, we propose a novel system, SynaptiQA, which integrates LLMs with Knowledge Graphs (KGs) to answer more questions about knowledge. Our approach leverages the generative capabilities of LLMs to create and optimize KG queries, thereby improving the accuracy and contextual relevance of responses. Experimental results in an industrial data set demonstrate that SynaptiQA outperforms baseline models and naive retrieval-augmented generation (RAG) systems, demonstrating improved accuracy and reduced hallucinations. This integration of KGs with LLMs paves the way for more reliable and interpretable domain-specific question answering systems.

# Summary. An optional shortened abstract.
# summary: 

featured: false

---
